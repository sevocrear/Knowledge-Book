## Свёртки в CNN, размеры карт признаков и число параметров

### Contents

1. Введение: что делает свёртка
2. Почему в CNN так часто используют свёртки `3×3` и нечётные ядра
3. Почему большие свёртки `5×5`, `7×7` считаются неэффективными
4. Формула размера feature map после Conv и Pooling
5. Что такое DeConv / Transposed Convolution
6. Как считать число обучаемых параметров
7. Как бы я объяснил это 5‑летнему ребёнку
8. References

---

### 1. Введение: что делает свёртка

Свёрточный слой в CNN берёт входное изображение или feature map и для каждой маленькой области (окна) применяет обучаемый фильтр (kernel). Результат — новая карта признаков, где каждый пиксель является взвешенной суммой окрестности входа, пропущенной через нелинейность.

Интуитивно:

- **окно (ядро)** задаёт, какую локальную структуру мы хотим «увидеть» (края, текстуры, формы);
- **stride** управляет тем, как плотно мы сдвигаем окно;
- **padding** управляет тем, что происходит на границах (обрезаем или добавляем нули);
- стек свёрток даёт всё более абстрактные признаки и увеличивает receptive field.

---

### 2. Почему в CNN так часто используют свёртки `3×3` и нечётные ядра

#### 2.1. Баланс «качество / цена» у `3×3`

Пусть у нас один входной канал. Тогда число весов в одном фильтре:

- `3×3` → 9 весов;
- `5×5` → 25 весов;
- `7×7` → 49 весов.

Стоимость по памяти и FLOPs растёт как $K^2$, где $K$ — размер ядра. При этом:

- две свёртки `3×3` подряд дают receptive field, эквивалентный примерно одной `5×5`;
- три свёртки `3×3` подряд дают receptive field как у одной `7×7`.

Но:

- параметров у стека из `3×3` меньше, чем у одной большой свёртки;
- между слоями появляются дополнительные нелинейности (ReLU, BatchNorm), что увеличивает выразительность модели.

Поэтому современные архитектуры (VGG, ResNet, EfficientNet и др.) предпочитают использовать **много `3×3` вместо единичных `5×5` или `7×7`**.

#### 2.2. Почему ядра обычно нечётные (`3×3`, `5×5`, `7×7`)

У нечётного ядра есть один чётко определённый центр — центральный пиксель окна. Это удобно:

- легко задать симметричный padding (слева/справа одинаковое число пикселей);
- проще интерпретировать, относительно какого пикселя считаем окрестность;
- уменьшаются артефакты смещения (shift).

У чётных ядер (`2×2`, `4×4`) центр оказывается «между» пикселями, приходится использовать несимметричный padding, что может вносить сдвиги и делает архитектуру менее аккуратной.

---

### 3. Почему большие свёртки `5×5`, `7×7` считаются неэффективными

**1. Они сильно дороже по параметрам и FLOPs.**

При фиксированных `in_channels` и `out_channels`:

- переход от `3×3` к `5×5` почти утрояет число параметров;
- переход к `7×7` увеличивает число параметров более чем в 5 раз.

**2. Их легко заменить стеком маленьких свёрток.**

Пример (на один канал):

- одна `5×5`: $25$ весов;
- две `3×3`: $9 + 9 = 18$ весов.

Receptive field почти тот же, параметров меньше, а между свёртками можно вставить ReLU и BatchNorm, что улучшает представление.

**3. Где всё-таки используют большие ядра**

- в самом первом слое сети (классический пример — `7×7` в старых ResNet на ImageNet);
- в специализированных архитектурах (например, factorized kernels `1×7`, `7×1` в Inception).

В современных сетях даже первый `7×7` всё чаще заменяют на несколько `3×3` или patch-embedding.

---

### 4. Формула размера feature map после Conv и Pooling

Обозначения:

- входная карта: высота $H_{in}$, ширина $W_{in}$;
- ядро: размер $K$ (предполагаем квадратное ядро $K \times K$);
- padding: $P$;
- stride: $S$;
- dilation: $D$ (обычно $D = 1$).

Общая формула для Conv2d / MaxPool2d / AvgPool2d:

$$
H_{out} = \left\lfloor \frac{H_{in} + 2P - D \cdot (K - 1) - 1}{S} + 1 \right\rfloor, \quad
W_{out} = \left\lfloor \frac{W_{in} + 2P - D \cdot (K - 1) - 1}{S} + 1 \right\rfloor.
$$

Без дилатации ($D = 1$):

$$
H_{out} = \left\lfloor \frac{H_{in} + 2P - K}{S} + 1 \right\rfloor, \quad
W_{out} = \left\lfloor \frac{W_{in} + 2P - K}{S} + 1 \right\rfloor.
$$

**Типичные случаи:**

- Conv `3×3`, `padding=1`, `stride=1`:
  - $H_{out} = H_{in}$, $W_{out} = W_{in}$ — размер сохраняется.
- Conv `3×3`, `padding=1`, `stride=2`:
  - примерно вдвое уменьшает размер (с округлением вниз).

---

### 5. Что такое DeConv / Transposed Convolution

Термин «DeConv» часто используют неформально. Правильное название операции — **Transposed Convolution** (transposed conv).

Важно: это **не математическая «обратная свёртка»**, а операция, которая:

- принимает feature map меньшего размера;
- с помощью обучаемого ядра и «обратной» геометрии stride/padding;
- выдаёт feature map большего размера (то есть выполняет upsampling с обучаемыми весами).

Transposed Conv активно используется:

- в декодерах автоэнкодеров;
- в архитектурах для сегментации (U‑Net, SegNet);
- в генераторах GAN для поэтапного увеличения разрешения изображения.

Формула размера выхода для ConvTranspose2d:

Пусть:

- вход: $H_{in}$;
- ядро: $K$;
- stride: $S$;
- padding: $P$;
- dilation: $D$;
- `output_padding` = $OP$.

Тогда:

$$
H_{out} = (H_{in} - 1) \cdot S - 2P + D \cdot (K - 1) + OP + 1.
$$

Аналогично считается $W_{out}$.

В PyTorch это реализовано как `nn.ConvTranspose2d`.

---

### 6. Как считать число обучаемых параметров

#### 6.1. Полносвязный слой (Linear / Dense)

Пусть:

- `in_features` — размер входного вектора;
- `out_features` — размер выхода;
- `bias=True` или `False`.

Тогда:

- без смещения (bias):  
  $$\text{params} = in\_features \cdot out\_features;$$
- со смещением:  
  $$\text{params} = in\_features \cdot out\_features + out\_features.$$

Пример в PyTorch:

```python
linear = nn.Linear(in_features=128, out_features=64, bias=True)
# params = 128 * 64 + 64
```

#### 6.2. Свёрточный слой Conv2d

Пусть:

- `in_channels` — число входных каналов;
- `out_channels` — число выходных каналов;
- ядро: `K_h × K_w`;
- `bias=True` или `False`.

На один выходной канал:

- весов ядра: `in_channels * K_h * K_w`;
- плюс, если есть bias: ещё `1` параметр.

Итого:

- без bias:

  $$
  \text{params} = out\_channels \cdot in\_channels \cdot K_h \cdot K_w;
  $$

- с bias:

  $$
  \text{params} = out\_channels \cdot (in\_channels \cdot K_h \cdot K_w + 1).
  $$

**Пример:**

```python
conv1 = nn.Conv2d(in_channels=4, out_channels=5, kernel_size=3)  # по умолчанию bias=True
count = 0
for p in conv1.parameters():
    count += p.numel()
print(f'Число обучаемых параметров: {count}')
```

Ручной расчёт:

- `in_channels = 4`, `out_channels = 5`, `K_h = K_w = 3`;
- весов на один выходной канал: `4 * 3 * 3 = 36`;
- плюс bias: `+1` → `37` параметров на фильтр;
- всего фильтров: `5`;
- итого: `5 * 37 = 185` параметров (это и вернёт код).

#### 6.3. Depthwise и Separable свёртки

- **Depthwise Conv** (`groups = in_channels`, `out_channels = in_channels`):

  $$
  \text{params} = in\_channels \cdot K_h \cdot K_w + (\text{bias?})
  $$

- **Pointwise Conv (`1×1`)**:

  $$
  \text{params} = in\_channels \cdot out\_channels + (\text{bias?})
  $$

Многие лёгкие архитектуры (MobileNet и др.) используют комбинацию depthwise + pointwise, чтобы сильно уменьшить число параметров.

#### 6.4. BatchNorm

Для BatchNorm с числом каналов `C` обучаемые параметры:

- `γ` (scale) — размер `C`;
- `β` (shift) — размер `C`.

Итого:

$$
\text{params} = 2 \cdot C.
$$

Статистики среднего и дисперсии считаются running‑статистикой и обычно не считаются обучаемыми параметрами.

---

### 7. Как бы я объяснил это 5‑летнему ребёнку

- Свёртка — это маленькое окошко, через которое сеть смотрит на картинку. Окошко `3×3` лёгкое и удобное, а если смотреть много раз, можно увидеть большой кусок картинки.
- Большие окошки `5×5` и `7×7` тяжёлые: считать с ними долго, а пользы не намного больше, чем от нескольких маленьких.
- DeConv — это волшебная лупа: из маленькой картинки делает большую и старается красиво дорисовать детали.
- Число параметров — это сколько ручек‑крутилок у модели. В свёртке мы просто считаем, сколько чисел в каждом фильтре, и умножаем на количество фильтров.

---

### 8. References

- **Связанные документы в этом knowledge‑book**:
  - `non-maximum-suppression-nms.md` — использует CNN‑детекторы, в которых все эти свёртки реально применяются.
  - `unscented-kalman-filter-and-tracking.md` — про трекинг объектов, который часто идёт следом за CNN‑детекцией.
  - `deep-reinforcement-learning.md` — в разделах про визуальное RL часто используются CNN‑фронтенды.

